{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361d73a1",
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2024-04-08T18:51:47.130888",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.123877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadbd56",
   "metadata": {
    "papermill": {
     "duration": 12.650384,
     "end_time": "2024-04-08T18:51:59.788340",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.137956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64eb379-e527-46c4-8b12-ead8db628070",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2de5d",
   "metadata": {
    "papermill": {
     "duration": 0.007241,
     "end_time": "2024-04-08T18:51:59.803571",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.796330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32fb60",
   "metadata": {
    "papermill": {
     "duration": 0.016983,
     "end_time": "2024-04-08T18:51:59.828208",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.811225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    FILENAME = 'Wav2Vec'\n",
    "    \n",
    "    SR = 32000\n",
    "    N_MFCC = 40\n",
    "    TARGET_LENGTH = 1024\n",
    "    \n",
    "    # Dataset\n",
    "    ROOT_DIR = 'C:/HongBeomsun/Dataset_SSD/FakeVoice'\n",
    "    \n",
    "    # Training\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 64\n",
    "    N_EPOCHS = 70\n",
    "    LEARNING_RATE = 3e-4\n",
    "    \n",
    "    # Others\n",
    "    SEED = 42\n",
    "    \n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700bf8e-7f43-4eac-9bea-25eb1d95fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CONFIG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a91730",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(CONFIG.ROOT_DIR,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7481719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db53f2f7",
   "metadata": {},
   "source": [
    "### Data Argumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ed7a4",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c02a7d-dfb6-4f8b-8df1-db2abaa1cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CONFIG.SEED, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'].value_counts()\n",
    "val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d3d15-b971-49e2-a410-71b4cd9cbcf4",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.01*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp * np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    stretch_data = librosa.effects.time_stretch(data, rate=rate)\n",
    "    return stretch_data\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    pitch_data = librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=pitch_factor)\n",
    "    return pitch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filepath, sr):\n",
    "    waveform, sr = torchaudio.load(filepath)\n",
    "    return waveform, sr\n",
    "\n",
    "def extract_features(waveform, sr, target_length):\n",
    "    mel_spec = MelSpectrogram(sr)(waveform)\n",
    "    db_spec = AmplitudeToDB()(mel_spec)\n",
    "    \n",
    "    if db_spec.shape[-1] < target_length:\n",
    "        pad_amount = target_length - db_spec.shape[-1]\n",
    "        db_spec = F.pad(db_spec, (0, pad_amount))\n",
    "        \n",
    "    else:\n",
    "        db_spec = db_spec[:, :, :target_length]\n",
    "        \n",
    "    return db_spec\n",
    "\n",
    "def normalize_volume(y, target_dB=-20):\n",
    "    rms = np.sqrt(np.mean(y**2))\n",
    "    loudness = 20 * np.log10(rms)\n",
    "    loudness_change_dB = target_dB - loudness\n",
    "    y_normalized = y * (10 ** (loudness_change_dB / 20))\n",
    "    return y_normalized\n",
    "\n",
    "def augment_data(y, sr):\n",
    "    augmented_data = []\n",
    "    augmented_data.append(noise(y))\n",
    "    augmented_data.append(stretch(y))\n",
    "    augmented_data.append(pitch(y, sr))\n",
    "    return augmented_data\n",
    "\n",
    "def create_void_data(data, sr):\n",
    "    void_data = np.zeros_like(data)\n",
    "    void_data = noise(void_data)\n",
    "    return void_data\n",
    "\n",
    "def create_duo_data(data1, data2, sr):\n",
    "    if len(data1) > len(data2):\n",
    "        data2 = np.pad(data2, (0, len(data1)-len(data2)), 'constant')\n",
    "    else:\n",
    "        data1 = np.pad(data1, (0, len(data2)-len(data1)), 'constant')\n",
    "        \n",
    "    duo_data = data1 + data2\n",
    "    max_val = np.max(np.abs(duo_data))\n",
    "    if max_val > 1:\n",
    "        duo_data = duo_data / max_val\n",
    "    \n",
    "    return duo_data\n",
    "\n",
    "def mix_two_random_data(df, sr):\n",
    "    idx1, idx2 = random.sample(range(len(df)), 2)\n",
    "    y1, _ = load_audio(os.path.join(CONFIG.ROOT_DIR, df.iloc[idx1]['path']), sr)\n",
    "    y2, _ = load_audio(os.path.join(CONFIG.ROOT_DIR, df.iloc[idx2]['path']), sr)\n",
    "    y_duo = create_duo_data(y1, y2, sr)\n",
    "    label_y1 = df.iloc[idx1]['label']\n",
    "    label_y2 = df.iloc[idx2]['label']\n",
    "    \n",
    "    label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
    "    label_vector[0 if label_y1 == 'fake' else 1] = 1\n",
    "    label_vector[0 if label_y2 == 'fake' else 1] = 1\n",
    "    \n",
    "    return y_duo, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdd0ba-fe6e-4efa-b785-af0389c50b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df, train_mode=True, augment=False):\n",
    "    features = []\n",
    "    labels = []\n",
    "    total = len(df)\n",
    "    \n",
    "    for i, (index, row) in enumerate(tqdm(df.iterrows(), total=total), 1):\n",
    "        y, sr = load_audio(os.path.join(CONFIG.ROOT_DIR, row['path']), CONFIG.SR)\n",
    "        \n",
    "        if train_mode:\n",
    "            label = row['label']\n",
    "            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
    "            label_vector[0 if label == 'fake' else 1] = 1\n",
    "            labels.append(label_vector)\n",
    "        \n",
    "        features.append(extract_features(y, sr, target_length=CONFIG.TARGET_LENGTH))\n",
    "        \n",
    "    if train_mode:\n",
    "        return features, labels\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e63871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    if augment:\n",
    "        augmented_features = []\n",
    "        augmented_labels = []\n",
    "        \n",
    "        num_mixed_samples = int(total * 0.1)\n",
    "        for _ in range(num_mixed_samples):\n",
    "            y_duo, y_duo_label = mix_two_random_data(df, CONFIG.SR)\n",
    "            augmented_features.append(extract_features(y_duo, CONFIG.SR))\n",
    "            augmented_labels.append(y_duo_label)\n",
    "        \n",
    "        num_augmented_samples = int(total * 0.2)\n",
    "        original_features = list(features)\n",
    "        original_labels = list(labels)\n",
    "        for idx in range(num_augmented_samples):\n",
    "            augmented_data = augment_data(original_features[idx], CONFIG.SR)\n",
    "            for aug_y in augmented_data:\n",
    "                augmented_features.append(extract_features(aug_y, CONFIG.SR))\n",
    "                augmented_labels.append(original_labels[idx])\n",
    "        \n",
    "        features.extend(augmented_features)\n",
    "        labels.extend(augmented_labels)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = get_features(train, train_mode=True, augment=True)\n",
    "val_features, val_labels = get_features(val, train_mode=True, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shape(features):\n",
    "    shapes = [feature.shape for feature in features]\n",
    "    unique_shape = set(shapes)\n",
    "    return unique_shape\n",
    "\n",
    "print(check_shape(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_np():\n",
    "    os.makedirs(os.path.join(CONFIG.ROOT_DIR, 'npy', CONFIG.FILENAME, 'npy'), exist_ok=True)\n",
    "    np.save(os.path.join(CONFIG.ROOT_DIR, 'npy', CONFIG.FILENAME, 'train_features.npy'), train_features)\n",
    "    np.save(os.path.join(CONFIG.ROOT_DIR, 'npy', CONFIG.FILENAME, 'train_labels.npy'), train_labels)\n",
    "    np.save(os.path.join(CONFIG.ROOT_DIR, 'npy', CONFIG.FILENAME, 'val_features.npy'), val_features)\n",
    "    np.save(os.path.join(CONFIG.ROOT_DIR, 'npy', CONFIG.FILENAME, 'val_labels.npy'), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02323f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np():\n",
    "    train_features = np.load(os.path.join(CONFIG.ROOT_DIR, CONFIG.FILENAME, 'train_features.npy'))\n",
    "    train_labels = np.load(os.path.join(CONFIG.ROOT_DIR, CONFIG.FILENAME, 'train_labels.npy'))\n",
    "    val_features = np.load(os.path.join(CONFIG.ROOT_DIR, CONFIG.FILENAME, 'val_features.npy'))\n",
    "    val_labels = np.load(os.path.join(CONFIG.ROOT_DIR, CONFIG.FILENAME, 'val_labels.npy'))\n",
    "    \n",
    "    return train_features, train_labels, val_features, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_np_in_chunks(data, dataname, chunk_size=10000):\n",
    "    os.makedirs(os.path.join(CONFIG.ROOT_DIR,'npy', CONFIG.FILENAME), exist_ok=True)\n",
    "    \n",
    "    total_chunks = len(data) // chunk_size + (1 if len(data) % chunk_size != 0 else 0)\n",
    "    for i in range(total_chunks):\n",
    "        chunk_data = data[i*chunk_size:(i+1)*chunk_size]\n",
    "        np.savez_compressed(os.path.join(CONFIG.ROOT_DIR, 'npy', CONFIG.FILENAME, f\"dataname_part{i+1}.npz\"), chunk_data)\n",
    "\n",
    "def load_np_in_chunks(total_chunks):\n",
    "    data = []\n",
    "    for i in range(total_chunks):\n",
    "        chunk_data = np.load(os.path.join(CONFIG.ROOT_DIR, 'npy', CONFIG.FILENAME, f\"dataname_part{i+1}.npz\"))['arr_0']\n",
    "        data.append(chunk_data)\n",
    "    return np.concatenate(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3efbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_np_in_chunks(train_features, 'train_features' , chunk_size=1000)\n",
    "save_np_in_chunks(train_labels, 'train_labels', chunk_size=1000)\n",
    "\n",
    "train_features = load_np_in_chunks(total_chunks=50)\n",
    "train_labels = load_np_in_chunks(total_chunks=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150de3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "val_features = np.array(val_features)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25233d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape, len(train_labels))\n",
    "print(val_features.shape, len(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb3435-cdb7-4a31-b7ef-fc16237cfc4a",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Tokenizer\n",
    "\n",
    "model_name = 'facebook/wav2vec2-base-960h'\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name, num_labels=CONFIG.N_CLASSES)\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_audio(audio):\n",
    "    input_values = tokenizer(audio, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    return input_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a682d49",
   "metadata": {
    "papermill": {
     "duration": 0.007331,
     "end_time": "2024-04-08T18:52:31.507909",
     "exception": false,
     "start_time": "2024-04-08T18:52:31.500578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2459913-1bf6-40b9-b07d-402699590b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, filepaths, labels):\n",
    "        self.filepaths = filepaths\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        filepath = self.filepaths[idx]\n",
    "        label = self.labels[idx]\n",
    "        waveform, sr = load_audio(filepath)\n",
    "        input_values = tokenize_audio(waveform)\n",
    "        return input_values, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a462f-e4b3-44d8-8eef-16000d3124d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_features, train_labels)\n",
    "val_dataset = CustomDataset(val_features, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1c7df-fbe7-4a61-9f66-c55138697eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a8cf22",
   "metadata": {},
   "source": [
    "### MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "mlflow.set_experiment('FakeVoice')\n",
    "\n",
    "def mlflow_run_decorator(run_name=None):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            mlflow.start_run(run_name=run_name)\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                mlflow.set_tag(\"Status\", \"SUCCEESS\")\n",
    "            except Exception as e:\n",
    "                mlflow.log_param(\"Exception\", e)\n",
    "                mlflow.set_tag(\"Status\", \"FAIL\")\n",
    "                raise e\n",
    "            finally:\n",
    "                mlflow.end_run()\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c4a8c-0219-46bd-bd46-09d0327fe7eb",
   "metadata": {},
   "source": [
    "### Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b19dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7253de-ce9a-45a8-b71f-7752e427941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mlflow_run_decorator(run_name=os.path.basename(__file__))\n",
    "def training(model, scheduler, optimizer, train_loader, val_loader, device):\n",
    "    mlflow.log_params(vars(CONFIG))\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    \n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CONFIG.N_EPOCHS+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for features, labels in tqdm(iter(train_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val AUC : [{_val_score:.5f}] LEARNING RATE : [{optimizer.param_groups[0][\"lr\"]:.5f}]')\n",
    "    \n",
    "        mlflow.log_metrics({'train_loss': _train_loss, 'val_loss': _val_loss, 'val_auc': _val_score}, step=epoch)\n",
    "        scheduler.step(_val_loss)\n",
    "            \n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffda5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiLabel_AUC(y_true, y_scores):\n",
    "    auc_scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
    "        auc_scores.append(auc)\n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    return mean_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(iter(val_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "            \n",
    "            loss = criterion(probs, labels)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        \n",
    "        # Calculate AUC score\n",
    "        auc_score = multiLabel_AUC(all_labels, all_probs)\n",
    "    \n",
    "    return _val_loss, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a482219-ce5e-47ce-90cc-564ceb4e46ff",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97644a0-2385-4e16-ab02-ecf787ac061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CONFIG.LEARNING_RATE)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "infer_model = training(model, scheduler, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978b0e6-b773-423a-93e4-ce463f4d4d84",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(CONFIG.ROOT_DIR, 'test.csv'))\n",
    "test_mfcc = get_features(test, train_mode=False, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76141516-342f-4f0f-8f75-20700f284792",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_mfcc, None)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e129df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(os.path.join(CONFIG.ROOT_DIR, 'npy/test_VariousFeatures_1000.npy'), test_mfcc)\n",
    "# test_mfcc = np.load(os.path.join(CONFIG.ROOT_DIR, 'npy/test_VariousFeatures_1000.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889b493-d760-4cac-9ced-c3715195e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for features in tqdm(iter(test_loader)):\n",
    "            features = features.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74fe5f-82f1-4ad7-818f-509e1bea642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fae66d-8f54-46d5-9201-0f4b0db76e76",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8314c4-1dce-4f79-9f3d-77d320a3746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(os.path.join(CONFIG.ROOT_DIR,'./sample_submission.csv'))\n",
    "submit.iloc[:, 1:] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d71bc-6703-40f7-9716-a0ef897eca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(f'./output/submit_MLP_Augment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277110b6",
   "metadata": {},
   "source": [
    "### AfterTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bc79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(torch.tensor(train_features).float().to(device)).cpu().detach().numpy()[:10])\n",
    "print(train_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((train_labels[:, 0] == 1) & (train_labels[:, 1] == 1))[0]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 4732842,
     "sourceId": 8066583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1830.928153,
   "end_time": "2024-04-08T19:22:15.265404",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T18:51:44.337251",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01a8f214ec354c44b73d439565382278": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06a1ede084cd487ebf3c469be657b53e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80013ce73542415e82be091acccb89fe",
        "IPY_MODEL_d280070ca871485fbd2b7d34b1c9fd10",
        "IPY_MODEL_8212bde7695f494cbabea66983e4cf29"
       ],
       "layout": "IPY_MODEL_c4da594b806c4c2bbff6e8cdaf6088eb"
      }
     },
     "37e28ba3d8564da4a3257c3729310584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80013ce73542415e82be091acccb89fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_95e72a34a4374fd5b4b147772085bb7c",
       "placeholder": "​",
       "style": "IPY_MODEL_37e28ba3d8564da4a3257c3729310584",
       "value": "model.safetensors: 100%"
      }
     },
     "8212bde7695f494cbabea66983e4cf29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d9e4e04bb60e40d6b46d782f8156d05f",
       "placeholder": "​",
       "style": "IPY_MODEL_b1fa83d0511a4d8a910b8fdb40d32c29",
       "value": " 36.5M/36.5M [00:01&lt;00:00, 41.1MB/s]"
      }
     },
     "95e72a34a4374fd5b4b147772085bb7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1fa83d0511a4d8a910b8fdb40d32c29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4da594b806c4c2bbff6e8cdaf6088eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d280070ca871485fbd2b7d34b1c9fd10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01a8f214ec354c44b73d439565382278",
       "max": 36494688,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dcd2393d73d14514851a7d9ef50315fc",
       "value": 36494688
      }
     },
     "d9e4e04bb60e40d6b46d782f8156d05f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcd2393d73d14514851a7d9ef50315fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
